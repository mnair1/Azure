{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "# Amazon Rekognition is a service that makes it easy to add powerful visual analysis to your applications. \n",
    "# Rekognition Image lets you easily build powerful applications to search, verify, and organize millions of images. \n",
    "# Rekognition Video lets you extract motion-based context from stored or live stream videos and helps you analyze them.\n",
    "# Rekognition detects objects, scenes, and faces; extracts text; recognizes celebrities; and identifies inappropriate \n",
    "# content in images. It also allows you to search and compare faces. Rekognition Image is based on the same proven, \n",
    "# highly scalable, deep learning technology developed by Amazon’s computer vision scientists to analyze billions of \n",
    "# images daily for Prime Photos.\n",
    "# ------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>13</td><td>application_1563383786914_0014</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-32-16-63.ec2.internal:20888/proxy/application_1563383786914_0014/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-32-21-242.ec2.internal:8042/node/containerlogs/container_1563383786914_0014_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Import Python Libraries. Press run.\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "import boto3\n",
    "import requests\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# Create the Spark Context and a boto3 client for accessing rekognition API's, Press run.\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "client = boto3.client('rekognition', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Canine\n",
      "Confidence: 98.9973678589\n",
      "Label: Mammal\n",
      "Confidence: 98.9973678589\n",
      "Label: Animal\n",
      "Confidence: 98.9973678589\n",
      "Label: Dog\n",
      "Confidence: 98.9973678589\n",
      "Label: Pet\n",
      "Confidence: 98.9973678589\n",
      "Label: Labrador Retriever\n",
      "Confidence: 94.2466583252\n",
      "Label: Golden Retriever\n",
      "Confidence: 86.29271698\n",
      "Label: Puppy\n",
      "Confidence: 56.5784339905"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------\n",
    "# Lets perform a simple Rekognition. I have placed an image of a dog on S3. The dog\n",
    "# is a Labrador Retriever. Let's see how Rekognition describes this image. Press run.\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "s3bucket='ai-operations-111'\n",
    "photo='rekognition/dog.jpg'\n",
    "\n",
    "response = client.detect_labels(Image={'S3Object':{'Bucket':s3bucket,'Name':photo}}, MaxLabels=10)\n",
    "\n",
    "for label in response['Labels']:\n",
    "    print (\"Label: \" + label['Name'])\n",
    "    print (\"Confidence: \" + str(label['Confidence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------\n",
    "# Note the labels attached to the image. A label is an object, scene, or concept found in \n",
    "# an image based on its contents.\n",
    "# Also note the confidence for each lable. A confidence score is a number between 0 and 100 \n",
    "# that indicates the probability that a given prediction is correct.\n",
    "# Highlight next cell and Press run.\n",
    "# --------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------\n",
    "# Lets perform another Rekognition. This time the image is of police officer standing in\n",
    "# outside the subway station under a street sign.\n",
    "# Highlight next cell and Press run.\n",
    "# --------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Person\n",
      "Confidence: 99.5062103271\n",
      "Label: Human\n",
      "Confidence: 99.5062103271\n",
      "Label: People\n",
      "Confidence: 69.2416687012\n",
      "Label: Urban\n",
      "Confidence: 66.0869140625\n",
      "Label: Police\n",
      "Confidence: 64.0607910156"
     ]
    }
   ],
   "source": [
    "photo='rekognition/police-sign.jpg'\n",
    "\n",
    "response = client.detect_labels(Image={'S3Object':{'Bucket':s3bucket,'Name':photo}}, MaxLabels=10)\n",
    "\n",
    "for label in response['Labels']:\n",
    "    print (\"Label: \" + label['Name'])\n",
    "    print (\"Confidence: \" + str(label['Confidence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# How cool it would be if the street sign could be read as text. Imagine the possibilities that\n",
    "# could open up. Text in Image is a capability of Amazon Rekognition that allows you to detect and recognize \n",
    "# text within an image, such as street names, captions, product names, and vehicular license plates.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected text\n",
      "Detected text:7\n",
      "Confidence: 99.56%\n",
      "Id: 0\n",
      "Type:LINE\n",
      "\n",
      "Detected text:90 St-Eimhurst Av\n",
      "Confidence: 98.77%\n",
      "Id: 1\n",
      "Type:LINE\n",
      "\n",
      "Detected text:Station\n",
      "Confidence: 99.91%\n",
      "Id: 2\n",
      "Type:LINE\n",
      "\n",
      "Detected text:12-6 12\n",
      "Confidence: 94.68%\n",
      "Id: 3\n",
      "Type:LINE\n",
      "\n",
      "Detected text:Av\n",
      "Confidence: 97.67%\n",
      "Id: 7\n",
      "Parent Id: 1\n",
      "Type:WORD\n",
      "\n",
      "Detected text:7\n",
      "Confidence: 99.56%\n",
      "Id: 4\n",
      "Parent Id: 0\n",
      "Type:WORD\n",
      "\n",
      "Detected text:90\n",
      "Confidence: 99.68%\n",
      "Id: 5\n",
      "Parent Id: 1\n",
      "Type:WORD\n",
      "\n",
      "Detected text:St-Eimhurst\n",
      "Confidence: 98.95%\n",
      "Id: 6\n",
      "Parent Id: 1\n",
      "Type:WORD\n",
      "\n",
      "Detected text:Station\n",
      "Confidence: 99.91%\n",
      "Id: 8\n",
      "Parent Id: 2\n",
      "Type:WORD\n",
      "\n",
      "Detected text:12-6\n",
      "Confidence: 94.65%\n",
      "Id: 9\n",
      "Parent Id: 3\n",
      "Type:WORD\n",
      "\n",
      "Detected text:12\n",
      "Confidence: 94.72%\n",
      "Id: 10\n",
      "Parent Id: 3\n",
      "Type:WORD"
     ]
    }
   ],
   "source": [
    "photo='rekognition/police-sign.jpg'\n",
    "\n",
    "response = client.detect_text(Image={'S3Object':{'Bucket':s3bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    print ('Detected text:' + text['DetectedText'])\n",
    "    print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "    print ('Id: {}'.format(text['Id']))\n",
    "    if 'ParentId' in text:\n",
    "        print ('Parent Id: {}'.format(text['ParentId']))\n",
    "    print ('Type:' + text['Type'])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Notice the Detected Text fields above. Rekognition correctly detected the text from the street sign as\n",
    "# 90 Saint.Eimhurst Av.. It also recognized another piece of text from a yellow parking lot sign.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Amazon Rekognition’s Celebrity Recognition is a deep learning based easy-to-use API for detection and \n",
    "# recognition of individuals who are famous, noteworthy, or prominent in their field. Let's see how Celebrity \n",
    "# Recognition works.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'UnrecognizedFaces': [{u'BoundingBox': {u'Width': 0.19218750298023224, u'Top': 0.17499999701976776, u'Left': 0.668749988079071, u'Height': 0.2541666626930237}, u'Confidence': 99.98306274414062, u'Pose': {u'Yaw': -6.714562892913818, u'Roll': -10.34298038482666, u'Pitch': -2.442352056503296}, u'Quality': {u'Sharpness': 89.91268920898438, u'Brightness': 78.94898986816406}, u'Landmarks': [{u'Y': 0.2834908664226532, u'X': 0.7244343161582947, u'Type': u'eyeLeft'}, {u'Y': 0.26826658844947815, u'X': 0.7874240875244141, u'Type': u'eyeRight'}, {u'Y': 0.3292079567909241, u'X': 0.7613192796707153, u'Type': u'nose'}, {u'Y': 0.3728090226650238, u'X': 0.7439817190170288, u'Type': u'mouthLeft'}, {u'Y': 0.35610678791999817, u'X': 0.797446072101593, u'Type': u'mouthRight'}]}, {u'BoundingBox': {u'Width': 0.16875000298023224, u'Top': 0.22708334028720856, u'Left': 0.36250001192092896, u'Height': 0.22499999403953552}, u'Confidence': 99.9433364868164, u'Pose': {u'Yaw': 9.292391777038574, u'Roll': -1.0646686553955078, u'Pitch': -7.5092620849609375}, u'Quality': {u'Sharpness': 73.4422378540039, u'Brightness': 71.79641723632812}, u'Landmarks': [{u'Y': 0.32007503509521484, u'X': 0.41931620240211487, u'Type': u'eyeLeft'}, {u'Y': 0.31983262300491333, u'X': 0.47707709670066833, u'Type': u'eyeRight'}, {u'Y': 0.37053802609443665, u'X': 0.4551214575767517, u'Type': u'nose'}, {u'Y': 0.40105849504470825, u'X': 0.4234135150909424, u'Type': u'mouthLeft'}, {u'Y': 0.40046024322509766, u'X': 0.47813740372657776, u'Type': u'mouthRight'}]}], u'CelebrityFaces': [{u'MatchConfidence': 100.0, u'Face': {u'BoundingBox': {u'Width': 0.25, u'Top': 0.2958333194255829, u'Left': 0.12812499701976776, u'Height': 0.3333333432674408}, u'Confidence': 99.92058563232422, u'Pose': {u'Yaw': 9.268149375915527, u'Roll': -19.350360870361328, u'Pitch': -9.697746276855469}, u'Quality': {u'Sharpness': 98.57371520996094, u'Brightness': 67.17218780517578}, u'Landmarks': [{u'Y': 0.44734710454940796, u'X': 0.20180866122245789, u'Type': u'eyeLeft'}, {u'Y': 0.4118923246860504, u'X': 0.282216340303421, u'Type': u'eyeRight'}, {u'Y': 0.5019076466560364, u'X': 0.2700166702270508, u'Type': u'nose'}, {u'Y': 0.5661360621452332, u'X': 0.23448686301708221, u'Type': u'mouthLeft'}, {u'Y': 0.530217707157135, u'X': 0.3082653880119324, u'Type': u'mouthRight'}]}, u'Name': u'Stephen Hawking', u'Urls': [u'www.imdb.com/name/nm0370071'], u'Id': u'3IT9O9a'}], 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '8eff44e4-a8e2-11e9-a468-f72325190772', 'HTTPHeaders': {'date': 'Wed, 17 Jul 2019 22:31:04 GMT', 'x-amzn-requestid': '8eff44e4-a8e2-11e9-a468-f72325190772', 'content-length': '2161', 'content-type': 'application/x-amz-json-1.1', 'connection': 'keep-alive'}}, u'OrientationCorrection': u'ROTATE_0'}"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Stephen_Hawking_David_Fleming_Martin_Curley.png/640px-Stephen_Hawking_David_Fleming_Martin_Curley.png')\n",
    "response_content = response.content\n",
    "\n",
    "rekognition_response = client.recognize_celebrities(Image={'Bytes': response_content})\n",
    "\n",
    "print(rekognition_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Notice the Name tag in the output above. The image was correctly identified as famous physicist Stephen Hawking.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'UnrecognizedFaces': [], u'CelebrityFaces': [{u'MatchConfidence': 100.0, u'Face': {u'BoundingBox': {u'Width': 0.4000000059604645, u'Top': 0.11428571492433548, u'Left': 0.2818181812763214, u'Height': 0.27936509251594543}, u'Confidence': 99.99872589111328, u'Pose': {u'Yaw': -20.682628631591797, u'Roll': 10.413687705993652, u'Pitch': 9.973031044006348}, u'Quality': {u'Sharpness': 98.09814453125, u'Brightness': 78.874755859375}, u'Landmarks': [{u'Y': 0.218977689743042, u'X': 0.4298885464668274, u'Type': u'eyeLeft'}, {u'Y': 0.23248927295207977, u'X': 0.545676589012146, u'Type': u'eyeRight'}, {u'Y': 0.2656586170196533, u'X': 0.44726768136024475, u'Type': u'nose'}, {u'Y': 0.31696897745132446, u'X': 0.40985748171806335, u'Type': u'mouthLeft'}, {u'Y': 0.32582390308380127, u'X': 0.5094131827354431, u'Type': u'mouthRight'}]}, u'Name': u'Shah Rukh Khan', u'Urls': [u'www.imdb.com/name/nm0451321'], u'Id': u'ok8hG6S'}], 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '9e619091-a8e2-11e9-ae57-617a1e32ad1d', 'HTTPHeaders': {'date': 'Wed, 17 Jul 2019 22:31:28 GMT', 'x-amzn-requestid': '9e619091-a8e2-11e9-ae57-617a1e32ad1d', 'content-length': '846', 'content-type': 'application/x-amz-json-1.1', 'connection': 'keep-alive'}}, u'OrientationCorrection': u'ROTATE_0'}"
     ]
    }
   ],
   "source": [
    "url='https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Shah_Rukh_Khan_graces_the_launch_of_the_new_Santro.jpg/220px-Shah_Rukh_Khan_graces_the_launch_of_the_new_Santro.jpg'\n",
    "    \n",
    "response = requests.get(url)\n",
    "response_content = response.content\n",
    "\n",
    "rekognition_response = client.recognize_celebrities(Image={'Bytes': response_content})\n",
    "\n",
    "print(rekognition_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# This time the image was correctly identified as famous actor Shahrukh Khan.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Can Amazon Rekognition compare faces? It can. Face Comparison is the process of comparing one face to one \n",
    "# or more faces to measure similarity. I have uploaded 2 images of Tiger Woods for comparison. Let's see \n",
    "# how these faces compare.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Face (99.999961853%)\n",
      "Target Face (99.9999847412%)\n",
      "  Similarity : 99.3212509155%"
     ]
    }
   ],
   "source": [
    "KEY_SOURCE = \"rekognition/tiger1.jpg\"\n",
    "KEY_TARGET = \"rekognition/tiger2.jpg\"\n",
    "\n",
    "def compare_faces(bucket, key, bucket_target, key_target, threshold=80, region=\"us-east-1\"):\n",
    "    rekognition = boto3.client(\"rekognition\", region)\n",
    "    response = client.compare_faces(\n",
    "    SourceImage={\n",
    "          \"S3Object\": {\n",
    "          \"Bucket\": bucket,\n",
    "          \"Name\": key,\n",
    "          }\n",
    "        },\n",
    "        TargetImage={\n",
    "           \"S3Object\": {\n",
    "           \"Bucket\": bucket_target,\n",
    "           \"Name\": key_target,\n",
    "           }\n",
    "        },\n",
    "        SimilarityThreshold=threshold,\n",
    "        )\n",
    "    return response['SourceImageFace'], response['FaceMatches']\n",
    "\n",
    "\n",
    "source_face, matches = compare_faces(s3bucket, KEY_SOURCE, s3bucket, KEY_TARGET)\n",
    "\n",
    "# the main source face\n",
    "print \"Source Face ({Confidence}%)\".format(**source_face)\n",
    "#print \"matches: \"+str(matches)\n",
    "\n",
    "# one match for each target face\n",
    "for match in matches:\n",
    "    print \"Target Face ({Confidence}%)\".format(**match['Face'])\n",
    "    print \"  Similarity : {}%\".format(match['Similarity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Amazon Rekognition compared the faces and came to the conclusion that the two images are a perfect match \n",
    "# of Tiger Woods.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# This time lets compare Tiger Woods to a Tiger Woods look alike.\n",
    "# I have uploaded the image of Tiger Woods and his look alike for comparison. Let's see \n",
    "# how these faces compare.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Match"
     ]
    }
   ],
   "source": [
    "BUCKET = \"ai-opertions-111\"\n",
    "KEY_SOURCE = \"rekognition/tiger1.jpg\"\n",
    "KEY_TARGET = \"rekognition/tiger_not.jpg\"\n",
    "\n",
    "def compare_faces(bucket, key, bucket_target, key_target, threshold=80, region=\"eu-west-1\"):\n",
    "    rekognition = boto3.client(\"rekognition\", region)\n",
    "    response = client.compare_faces(\n",
    "    SourceImage={\n",
    "          \"S3Object\": {\n",
    "          \"Bucket\": bucket,\n",
    "          \"Name\": key,\n",
    "          }\n",
    "        },\n",
    "        TargetImage={\n",
    "           \"S3Object\": {\n",
    "           \"Bucket\": bucket_target,\n",
    "           \"Name\": key_target,\n",
    "           }\n",
    "        },\n",
    "        SimilarityThreshold=threshold,\n",
    "        )\n",
    "    return response['SourceImageFace'], response['FaceMatches']\n",
    "\n",
    "\n",
    "source_face, matches = compare_faces(s3bucket, KEY_SOURCE, s3bucket, KEY_TARGET)\n",
    "\n",
    "# the main source face\n",
    "#print \"Source Face ({Confidence}%)\".format(**source_face)\n",
    "if not matches:\n",
    "    print(\"Not a Match\")\n",
    "\n",
    "\n",
    "# one match for each target face\n",
    "for match in matches:\n",
    "    print \"Target Face ({Confidence}%)\".format(**match['Face'])\n",
    "    print \"  Similarity : {}%\".format(match['Similarity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# It's not a match!!\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'FaceModelVersions': [u'4.0'], 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': 'f80e1b06-a8e2-11e9-9196-6d3d535869aa', 'HTTPHeaders': {'date': 'Wed, 17 Jul 2019 22:33:58 GMT', 'x-amzn-requestid': 'f80e1b06-a8e2-11e9-9196-6d3d535869aa', 'content-length': '66', 'content-type': 'application/x-amz-json-1.1', 'connection': 'keep-alive'}}, u'CollectionIds': [u'rek-collection-1']}"
     ]
    }
   ],
   "source": [
    "COLLECTION = \"rek-collection-1\"\n",
    "client.create_collection(CollectionId=COLLECTION)\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Amazon Rekognition can store information about detected faces in server-side containers known as collections. \n",
    "# You can use the facial information that's stored in a collection to search for known faces in images, stored \n",
    "# videos, and streaming videos. Let' store the image of Tiger Woods in a new collection.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face (99.999961853%)\n",
      "  FaceId: b24dc9c5-24c4-4a6b-a84a-7f579b7104db\n",
      "  ImageId: 6dc6932d-3f30-3897-8a6a-5e792a811687"
     ]
    }
   ],
   "source": [
    "KEY = \"rekognition/tiger1.jpg\"\n",
    "IMAGE_ID = uuid.uuid4().hex  \n",
    "\n",
    "# Note: you have to create the collection first!\n",
    "#client.create_collection(CollectionId=COLLECTION)\n",
    "\n",
    "def index_faces(bucket, key, collection_id, image_id=None, attributes=(), region=\"us-east-1\"):\n",
    "\n",
    "    response = client.index_faces(\n",
    "                                 Image={\n",
    "                                 \"S3Object\": {\n",
    "                                 \"Bucket\": bucket,\n",
    "                                 \"Name\": key,\n",
    "                                 }\n",
    "                                 },\n",
    "                                 CollectionId=collection_id,\n",
    "                                 ExternalImageId=image_id,\n",
    "                                     DetectionAttributes=attributes,\n",
    "                                 )\n",
    "    return response['FaceRecords']\n",
    "\n",
    "\n",
    "for record in index_faces(s3bucket, KEY, COLLECTION, IMAGE_ID):\n",
    "    face = record['Face']\n",
    "    # details = record['FaceDetail']\n",
    "    print \"Face ({}%)\".format(face['Confidence'])\n",
    "    print \"  FaceId: {}\".format(face['FaceId'])\n",
    "    print \"  ImageId: {}\".format(face['ImageId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Now let's search for Tiger Woods in our collections database using a completely new picture.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Face (98.2003479004%)\n",
      "  FaceId : b24dc9c5-24c4-4a6b-a84a-7f579b7104db\n",
      "  ImageId : 7fed53a5cc9946aca903c5ec0e5becb2"
     ]
    }
   ],
   "source": [
    "KEY = \"rekognition/search_tiger.jpg\"\n",
    "\n",
    "def search_faces_by_image(bucket, key, collection_id, threshold=80, region=\"eu-west-1\"):\n",
    "    response = client.search_faces_by_image(\n",
    "                         Image={\n",
    "                         \"S3Object\": {\n",
    "                         \"Bucket\": bucket,\n",
    "                         \"Name\": key,\n",
    "                         }\n",
    "                         },\n",
    "                         CollectionId=collection_id,\n",
    "                         FaceMatchThreshold=threshold,\n",
    "                         )\n",
    "    return response['FaceMatches']\n",
    "\n",
    "for record in search_faces_by_image(s3bucket, KEY, COLLECTION):\n",
    "        face = record['Face']\n",
    "        print \"Matched Face ({}%)\".format(record['Similarity'])\n",
    "        print \"  FaceId : {}\".format(face['FaceId'])\n",
    "        print \"  ImageId : {}\".format(face['ExternalImageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Looks like the picture matched. Comparing faces within collections goes a long way in Master Data \n",
    "# Management  initiatives.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Now let's search for Will Smith in our collections database.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image not in our database"
     ]
    }
   ],
   "source": [
    "KEY = \"rekognition/will.jpg\"\n",
    "\n",
    "def search_faces_by_image(bucket, key, collection_id, threshold=80, region=\"eu-west-1\"):\n",
    "    response = client.search_faces_by_image(\n",
    "                 Image={\n",
    "                      \"S3Object\": {\n",
    "                      \"Bucket\": bucket,\n",
    "                      \"Name\": key,\n",
    "                 }\n",
    "                 },\n",
    "                 CollectionId=collection_id,\n",
    "                 FaceMatchThreshold=threshold,\n",
    "                 )\n",
    "    return response['FaceMatches']\n",
    "\n",
    "for record in search_faces_by_image(s3bucket, KEY, COLLECTION):\n",
    "        face = record['Face']\n",
    "        print \"Matched Face ({}%)\".format(record['Similarity'])\n",
    "        print \"  FaceId : {}\".format(face['FaceId'])\n",
    "        print \"  ImageId : {}\".format(face['ExternalImageId'])\n",
    "else:\n",
    "    print('Image not in our database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# Will Smith does not exist in our collections database.\n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'FaceModelVersions': [], 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '618ddc09-a8e3-11e9-bb3b-e914b68399d1', 'HTTPHeaders': {'date': 'Wed, 17 Jul 2019 22:36:55 GMT', 'x-amzn-requestid': '618ddc09-a8e3-11e9-bb3b-e914b68399d1', 'content-length': '43', 'content-type': 'application/x-amz-json-1.1', 'connection': 'keep-alive'}}, u'CollectionIds': []}"
     ]
    }
   ],
   "source": [
    "client.delete_collection(CollectionId=COLLECTION)\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# How can object detection within an image be useful? Imagine a security camera captured a man with a gun in a\n",
    "# busy mall. Image labels can be read by Data Science/Monitoring Algorithms and proper authorities could be \n",
    "# alerted before a mishap happens. \n",
    "# Highlight next cell and Press run.\n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Human\n",
      "Confidence: 97.282333374\n",
      "Label: Person\n",
      "Confidence: 97.282333374\n",
      "Label: Weaponry\n",
      "Confidence: 94.5300216675\n",
      "Label: Weapon\n",
      "Confidence: 94.5300216675\n",
      "Label: Gun\n",
      "Confidence: 94.5300216675\n",
      "Label: Handgun\n",
      "Confidence: 79.3459777832\n",
      "Label: Shotgun\n",
      "Confidence: 55.4469566345"
     ]
    }
   ],
   "source": [
    "photo='rekognition/pistol.jpg'\n",
    "\n",
    "response = client.detect_labels(Image={'S3Object':{'Bucket':s3bucket,'Name':photo}}, MaxLabels=10)\n",
    "\n",
    "for label in response['Labels']:\n",
    "    print (\"Label: \" + label['Name'])\n",
    "    print (\"Confidence: \" + str(label['Confidence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# The possibilities are endless. Everyday many large scale organizations are finding new ways to use this \n",
    "# technology. I hope you found this information both informative and useful. Amazon \n",
    "# Rekognition is covered in more detail in the AWS Big Data Speciality training. \n",
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
